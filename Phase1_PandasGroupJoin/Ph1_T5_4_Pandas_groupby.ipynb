{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e2e623",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Pandas: Groupby Operations and Transformations\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Jan 2025\n",
    "<p>Phase 1</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b0f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Categorical variable taking on a few discrete values.\n",
    "\n",
    "Each of these values form a group. Want to:\n",
    "- Calculate statistics on various quantities for each group (mean, etc.)\n",
    "- Transform/scale certain columns differently for each group.\n",
    "\n",
    "\n",
    "DataFrame.groupby() allows us to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1678c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take the Titanic dataset again:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 80,
=======
   "execution_count": 3,
>>>>>>> upstream/main
   "id": "3309b922",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 80,
=======
     "execution_count": 3,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titanic_df = pd.read_csv('Data/titanic.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05fa5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sex as  relevant categorical variable:\n",
    "- survival rate\n",
    "- distribution of ages\n",
    "- fare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd2c02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The groupby object"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 6,
>>>>>>> upstream/main
   "id": "0e82a941",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000175603EF4F0>"
      ]
     },
     "execution_count": 81,
=======
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021BA24A3750>"
      ]
     },
     "execution_count": 6,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset = titanic_df[['Sex', 'Survived', 'Age', 'Fare']]\n",
    "titanic_subset.groupby('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db31580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrameGroupBy in module pandas.core.groupby.generic object:\n",
      "\n",
      "class DataFrameGroupBy(pandas.core.groupby.groupby.GroupBy)\n",
      " |  DataFrameGroupBy(obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'None'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby.BaseGroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      typing.Generic\n",
      " |      pandas.core.groupby.indexing.GroupByIndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key) -> 'DataFrameGroupBy | SeriesGroupBy'\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list, dict or None\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |          - None, in which case ``**kwargs`` are used with Named Aggregation. Here the\n",
      " |            output has one column for each element in ``**kwargs``. The name of the\n",
      " |            column is keyword, whereas the value determines the aggregation used to compute\n",
      " |            the values in the column.\n",
      " |      \n",
      " |            Can also accept a Numba JIT function with\n",
      " |            ``engine='numba'`` specified. Only passing a single function is supported\n",
      " |            with this engine.\n",
      " |      \n",
      " |            If the ``'numba'`` engine is chosen, the function must be\n",
      " |            a user defined function with ``values`` and ``index`` as the\n",
      " |            first and second arguments respectively in the function signature.\n",
      " |            Each group's index will be passed to the user defined function\n",
      " |            and optionally available for use.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |      **kwargs\n",
      " |          * If ``func`` is None, ``**kwargs`` are used to define the output names and\n",
      " |            aggregations via Named Aggregation. See ``func`` entry.\n",
      " |          * Otherwise, keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby.apply : Apply function func group-wise\n",
      " |          and combine the results together.\n",
      " |      DataFrame.groupby.transform : Transforms the Series on each group\n",
      " |          based on the given function.\n",
      " |      DataFrame.aggregate : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"A\": [1, 1, 2, 2],\n",
      " |      ...         \"B\": [1, 2, 3, 4],\n",
      " |      ...         \"C\": [0.362838, 0.227877, 1.267767, -0.562860],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      User-defined function for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(lambda x: sum(x) + 2)\n",
      " |          B          C\n",
      " |      A\n",
      " |      1       5       2.590715\n",
      " |      2       9       2.704907\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590715\n",
      " |      2   3   4  0.704907\n",
      " |      \n",
      " |      To control the output names with different aggregations per column,\n",
      " |      pandas supports \"named aggregation\"\n",
      " |      \n",
      " |      >>> df.groupby(\"A\").agg(\n",
      " |      ...     b_min=pd.NamedAgg(column=\"B\", aggfunc=\"min\"),\n",
      " |      ...     c_sum=pd.NamedAgg(column=\"C\", aggfunc=\"sum\"))\n",
      " |         b_min     c_sum\n",
      " |      A\n",
      " |      1      1  0.590715\n",
      " |      2      3  0.704907\n",
      " |      \n",
      " |      - The keywords are the *output* column names\n",
      " |      - The values are tuples whose first element is the column to select\n",
      " |        and the second element is the aggregation to apply to that column.\n",
      " |        Pandas provides the ``pandas.NamedAgg`` namedtuple with the fields\n",
      " |        ``['column', 'aggfunc']`` to make it clearer what the arguments are.\n",
      " |        As usual, the aggregation can be a callable or a string alias.\n",
      " |      \n",
      " |      See :ref:`groupby.aggregate.named` for more.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the aggregating function.\n",
      " |      \n",
      " |      >>> df.groupby(\"A\")[[\"B\"]].agg(lambda x: x.astype(float).min())\n",
      " |            B\n",
      " |      A\n",
      " |      1   1.0\n",
      " |      2   3.0\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots: 'bool' = True, column=None, fontsize: 'int | None' = None, rot: 'int' = 0, grid: 'bool' = True, ax=None, figsize: 'tuple[float, float] | None' = None, layout=None, sharex: 'bool' = False, sharey: 'bool' = True, backend=None, **kwargs)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots : bool\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group.\n",
      " |      \n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby.\n",
      " |      fontsize : float or str\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          The layout of the plot: (rows, columns).\n",
      " |      sharex : bool, default False\n",
      " |          Whether x-axes will be shared among subplots.\n",
      " |      sharey : bool, default True\n",
      " |          Whether y-axes will be shared among subplots.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          matplotlib's boxplot function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      You can create boxplots for grouped data and show them as separate subplots:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> import itertools\n",
      " |          >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |          >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |          >>> data = np.random.randn(len(index),4)\n",
      " |          >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |          >>> grouped = df.groupby(level='lvl1')\n",
      " |          >>> grouped.boxplot(rot=45, fontsize=12, figsize=(8,10))  # doctest: +SKIP\n",
      " |      \n",
      " |      The ``subplots=False`` option shows the boxplots in a single figure.\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> grouped.boxplot(subplots=False, rot=45, fontsize=12)  # doctest: +SKIP\n",
      " |  \n",
      " |  corr(self, method: 'str | Callable[[np.ndarray, np.ndarray], float]' = 'pearson', min_periods: 'int' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |      \n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(min_periods=3)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   NaN\n",
      " |      cats   NaN   1.0\n",
      " |  \n",
      " |  corrwith(self, other: 'DataFrame | Series', axis: 'Axis | lib.NoDefault' = <no_default>, drop: 'bool' = False, method: 'CorrelationMethod' = 'pearson', numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
      " |      >>> columns = [\"one\", \"two\", \"three\", \"four\"]\n",
      " |      >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
      " |      >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
      " |      >>> df1.corrwith(df2)\n",
      " |      one      1.0\n",
      " |      two      1.0\n",
      " |      three    1.0\n",
      " |      four     1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df2.corrwith(df1, axis=1)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |          This argument is applicable only when no ``nan`` is in the dataframe.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\n",
      " |          covariance.\n",
      " |      core.window.expanding.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.rolling.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame | None' = None, method: 'FillnaOptions | None' = None, axis: 'Axis | None | lib.NoDefault' = <no_default>, inplace: 'bool' = False, limit: 'int | None' = None, downcast=<no_default>) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method within groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list. Users wanting to use the ``value`` argument and not ``method``\n",
      " |          should prefer :meth:`.DataFrame.fillna` as this\n",
      " |          will produce the same result and be more performant.\n",
      " |      method : {{'bfill', 'ffill', None}}, default None\n",
      " |          Method to use for filling holes. ``'ffill'`` will propagate\n",
      " |          the last valid observation forward within a group.\n",
      " |          ``'bfill'`` will use next valid observation to fill the gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values. When the :class:`DataFrameGroupBy`\n",
      " |          ``axis`` argument is ``0``, using ``axis=1`` here will produce\n",
      " |          the same results as :meth:`.DataFrame.fillna`. When the\n",
      " |          :class:`DataFrameGroupBy` ``axis`` argument is ``1``, using ``axis=0``\n",
      " |          or ``axis=1`` here will produce the same results.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Broken. Do not set to True.\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill within a group. In other words,\n",
      " |          if there is a gap with more than this number of consecutive NaNs,\n",
      " |          it will only be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ffill : Forward fill values within a group.\n",
      " |      bfill : Backward fill values within a group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"key\": [0, 0, 1, 1, 1],\n",
      " |      ...         \"A\": [np.nan, 2, np.nan, 3, np.nan],\n",
      " |      ...         \"B\": [2, 3, np.nan, np.nan, np.nan],\n",
      " |      ...         \"C\": [np.nan, np.nan, 2, np.nan, np.nan],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         key    A    B   C\n",
      " |      0    0  NaN  2.0 NaN\n",
      " |      1    0  2.0  3.0 NaN\n",
      " |      2    1  NaN  NaN 2.0\n",
      " |      3    1  3.0  NaN NaN\n",
      " |      4    1  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along columns.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"ffill\")\n",
      " |           A    B   C\n",
      " |      0  NaN  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  NaN  NaN 2.0\n",
      " |      3  3.0  NaN 2.0\n",
      " |      4  3.0  NaN 2.0\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"bfill\")\n",
      " |           A    B   C\n",
      " |      0  2.0  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  3.0  NaN 2.0\n",
      " |      3  3.0  NaN NaN\n",
      " |      4  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along rows.\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=\"ffill\").T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  0.0  2.0  2.0\n",
      " |      1  0.0  2.0  3.0  3.0\n",
      " |      2  1.0  1.0  NaN  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  1.0  NaN  NaN\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=\"bfill\").T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  NaN  2.0  NaN\n",
      " |      1  0.0  2.0  3.0  NaN\n",
      " |      2  1.0  NaN  2.0  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  NaN  NaN  NaN\n",
      " |      \n",
      " |      Only replace the first NaN element within a group along rows.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").fillna(method=\"ffill\", limit=1)\n",
      " |           A    B    C\n",
      " |      0  NaN  2.0  NaN\n",
      " |      1  2.0  3.0  NaN\n",
      " |      2  NaN  NaN  2.0\n",
      " |      3  3.0  NaN  2.0\n",
      " |      4  3.0  NaN  NaN\n",
      " |  \n",
      " |  filter(self, func, dropna: 'bool' = True, *args, **kwargs)\n",
      " |      Filter elements from groups that don't satisfy a criterion.\n",
      " |      \n",
      " |      Elements from groups are filtered if they do not satisfy the\n",
      " |      boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Criterion to apply to each group. Should return True or False.\n",
      " |      dropna : bool\n",
      " |          Drop groups that do not pass the filter. True by default; if False,\n",
      " |          groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |  \n",
      " |  hist(self, column: 'IndexLabel | None' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {{0 or 'index', 1 or 'columns'}}, default None\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |          If axis is not provided, grouper's axis is used.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {{0 or 'index', 1 or 'columns'}}, default None\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |          If axis is not provided, grouper's axis is used.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  nunique(self, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Return DataFrame with counts of unique elements in each position.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |            value1  value2\n",
      " |      id\n",
      " |      egg        1       1\n",
      " |      ham        1       2\n",
      " |      spam       2       1\n",
      " |      \n",
      " |      Check for rows with the same id but conflicting values:\n",
      " |      \n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  skew(self, axis: 'Axis | None | lib.NoDefault' = <no_default>, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs) -> 'DataFrame'\n",
      " |      Return unbiased skew within groups.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Axis for the function to be applied on.\n",
      " |      \n",
      " |          Specifying ``axis=None`` will apply the aggregation across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.skew : Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi',\n",
      " |      ...            'lion', 'monkey', 'rabbit'],\n",
      " |      ...           ['bird', 'bird', 'bird', 'bird',\n",
      " |      ...            'mammal', 'mammal', 'mammal']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class'))\n",
      " |      >>> df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan,\n",
      " |      ...                                  80.5, 21.5, 15.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      max_speed\n",
      " |      name     class\n",
      " |      falcon   bird        389.0\n",
      " |      parrot   bird         24.0\n",
      " |      cockatoo bird         70.0\n",
      " |      kiwi     bird          NaN\n",
      " |      lion     mammal       80.5\n",
      " |      monkey   mammal       21.5\n",
      " |      rabbit   mammal       15.0\n",
      " |      >>> gb = df.groupby([\"class\"])\n",
      " |      >>> gb.skew()\n",
      " |              max_speed\n",
      " |      class\n",
      " |      bird     1.628296\n",
      " |      mammal   1.669046\n",
      " |      >>> gb.skew(skipna=False)\n",
      " |              max_speed\n",
      " |      class\n",
      " |      bird          NaN\n",
      " |      mammal   1.669046\n",
      " |  \n",
      " |  take(self, indices: 'TakeIndexer', axis: 'Axis | None | lib.NoDefault' = <no_default>, **kwargs) -> 'DataFrame'\n",
      " |      Return the elements in the given *positional* indices in each group.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      If a requested index does not exist for some group, this method will raise.\n",
      " |      To get similar behavior that ignores indices that don't exist, see\n",
      " |      :meth:`.DataFrameGroupBy.nth`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An DataFrame containing the elements taken from each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.take : Take elements from a Series along an axis.\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan),\n",
      " |      ...                    ('rabbit', 'mammal', 15.0)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[4, 3, 2, 1, 0])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      4  falcon    bird      389.0\n",
      " |      3  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      0  rabbit  mammal       15.0\n",
      " |      >>> gb = df.groupby([1, 1, 2, 2, 2])\n",
      " |      \n",
      " |      Take elements at positions 0 and 1 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the indices selected in the result do not correspond to\n",
      " |      our input indices 0 and 1. That's because we are selecting the 0th\n",
      " |      and 1st rows, not rows whose indices equal 0 and 1.\n",
      " |      \n",
      " |      >>> gb.take([0, 1])\n",
      " |             name   class  max_speed\n",
      " |      1 4  falcon    bird      389.0\n",
      " |        3  parrot    bird       24.0\n",
      " |      2 2    lion  mammal       80.5\n",
      " |        1  monkey  mammal        NaN\n",
      " |      \n",
      " |      The order of the specified indices influences the order in the result.\n",
      " |      Here, the order is swapped from the previous example.\n",
      " |      \n",
      " |      >>> gb.take([1, 0])\n",
      " |             name   class  max_speed\n",
      " |      1 3  parrot    bird       24.0\n",
      " |        4  falcon    bird      389.0\n",
      " |      2 1  monkey  mammal        NaN\n",
      " |        2    lion  mammal       80.5\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> gb.take([-1, -2])\n",
      " |             name   class  max_speed\n",
      " |      1 3  parrot    bird       24.0\n",
      " |        4  falcon    bird      389.0\n",
      " |      2 0  rabbit  mammal       15.0\n",
      " |        1  monkey  mammal        NaN\n",
      " |  \n",
      " |  transform(self, func, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Call function producing a same-indexed DataFrame on each group.\n",
      " |      \n",
      " |      Returns a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function, str\n",
      " |          Function to apply to each group. See the Notes section below for requirements.\n",
      " |      \n",
      " |          Accepted inputs are:\n",
      " |      \n",
      " |          - String\n",
      " |          - Python function\n",
      " |          - Numba JIT function with ``engine='numba'`` specified.\n",
      " |      \n",
      " |          Only passing a single function is supported with this engine.\n",
      " |          If the ``'numba'`` engine is chosen, the function must be\n",
      " |          a user defined function with ``values`` and ``index`` as the\n",
      " |          first and second arguments respectively in the function signature.\n",
      " |          Each group's index will be passed to the user defined function\n",
      " |          and optionally available for use.\n",
      " |      \n",
      " |          If a string is chosen, then it needs to be the name\n",
      " |          of the groupby method you want to use.\n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or the global setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby.apply : Apply function ``func`` group-wise and combine\n",
      " |          the results together.\n",
      " |      DataFrame.groupby.aggregate : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      DataFrame.transform : Call ``func`` on self producing a DataFrame with the\n",
      " |          same axis shape as self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, if `f` returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results. See :ref:`gotchas.udf-mutation` for more details.\n",
      " |      \n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          When using ``.transform`` on a grouped DataFrame and the transformation function\n",
      " |          returns a DataFrame, pandas now aligns the result's index\n",
      " |          with the input's index. You can call ``.to_numpy()`` on the\n",
      " |          result of the transformation function to avoid alignment.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                           'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')[['C', 'D']]\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |              C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      Broadcast result of the transformation\n",
      " |      \n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |          C    D\n",
      " |      0  4.0  6.0\n",
      " |      1  3.0  8.0\n",
      " |      2  4.0  6.0\n",
      " |      3  3.0  8.0\n",
      " |      4  4.0  6.0\n",
      " |      5  3.0  8.0\n",
      " |      \n",
      " |      >>> grouped.transform(\"mean\")\n",
      " |          C    D\n",
      " |      0  3.666667  4.0\n",
      " |      1  4.000000  5.0\n",
      " |      2  3.666667  4.0\n",
      " |      3  4.000000  5.0\n",
      " |      4  3.666667  4.0\n",
      " |      5  4.000000  5.0\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |      The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |      for example:\n",
      " |      \n",
      " |      >>> grouped.transform(lambda x: x.astype(int).max())\n",
      " |      C  D\n",
      " |      0  5  8\n",
      " |      1  5  9\n",
      " |      2  5  8\n",
      " |      3  5  9\n",
      " |      4  5  8\n",
      " |      5  5  9\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame | Series'\n",
      " |      Return a Series or DataFrame containing counts of unique rows.\n",
      " |      \n",
      " |      .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of rows that contain NA values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Series if the groupby as_index is True, otherwise DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      DataFrame.value_counts: Equivalent method on DataFrame.\n",
      " |      SeriesGroupBy.value_counts: Equivalent method on SeriesGroupBy.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - If the groupby as_index is True then the returned Series will have a\n",
      " |        MultiIndex with one level per input column.\n",
      " |      - If the groupby as_index is False then the returned DataFrame will have an\n",
      " |        additional column with the value_counts. The column is labelled 'count' or\n",
      " |        'proportion', depending on the ``normalize`` parameter.\n",
      " |      \n",
      " |      By default, rows that contain any NA values are omitted from\n",
      " |      the result.\n",
      " |      \n",
      " |      By default, the result will be in descending order so that the\n",
      " |      first element of each group is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    'gender': ['male', 'male', 'female', 'male', 'female', 'male'],\n",
      " |      ...    'education': ['low', 'medium', 'high', 'low', 'high', 'low'],\n",
      " |      ...    'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR']\n",
      " |      ... })\n",
      " |      \n",
      " |      >>> df\n",
      " |              gender  education   country\n",
      " |      0       male    low         US\n",
      " |      1       male    medium      FR\n",
      " |      2       female  high        US\n",
      " |      3       male    low         FR\n",
      " |      4       female  high        FR\n",
      " |      5       male    low         FR\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts()\n",
      " |      gender  education  country\n",
      " |      female  high       FR         1\n",
      " |                         US         1\n",
      " |      male    low        FR         2\n",
      " |                         US         1\n",
      " |              medium     FR         1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts(ascending=True)\n",
      " |      gender  education  country\n",
      " |      female  high       FR         1\n",
      " |                         US         1\n",
      " |      male    low        US         1\n",
      " |              medium     FR         1\n",
      " |              low        FR         2\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.groupby('gender').value_counts(normalize=True)\n",
      " |      gender  education  country\n",
      " |      female  high       FR         0.50\n",
      " |                         US         0.50\n",
      " |      male    low        FR         0.50\n",
      " |                         US         0.25\n",
      " |              medium     FR         0.25\n",
      " |      Name: proportion, dtype: float64\n",
      " |      \n",
      " |      >>> df.groupby('gender', as_index=False).value_counts()\n",
      " |         gender education country  count\n",
      " |      0  female      high      FR      1\n",
      " |      1  female      high      US      1\n",
      " |      2    male       low      FR      2\n",
      " |      3    male       low      US      1\n",
      " |      4    male    medium      FR      1\n",
      " |      \n",
      " |      >>> df.groupby('gender', as_index=False).value_counts(normalize=True)\n",
      " |         gender education country  proportion\n",
      " |      0  female      high      FR        0.50\n",
      " |      1  female      high      US        0.50\n",
      " |      2    male       low      FR        0.50\n",
      " |      3    male       low      US        0.25\n",
      " |      4    male    medium      FR        0.25\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  plot\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |      \n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |      \n",
      " |            .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      rot : float, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : float, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> ser = pd.Series([1, 2, 3, 3])\n",
      " |          >>> plot = ser.plot(kind='hist', title=\"My plot\")\n",
      " |      \n",
      " |      For DataFrame:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},\n",
      " |          ...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> plot = df.plot(title=\"DataFrame Plot\")\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> lst = [-1, -2, -3, 1, 2, 3]\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> plot = ser.groupby(lambda x: x > 0).plot(title=\"SeriesGroupBy Plot\")\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\"col1\" : [1, 2, 3, 4],\n",
      " |          ...                   \"col2\" : [\"A\", \"B\", \"A\", \"B\"]})\n",
      " |          >>> plot = df.groupby(\"col2\").plot(kind=\"bar\", title=\"DataFrameGroupBy Plot\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  __orig_bases__ = (pandas.core.groupby.groupby.GroupBy[pandas.core.fram...\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr: 'str')\n",
      " |  \n",
      " |  __init__(self, obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  all(self, skipna: 'bool' = True)\n",
      " |      Return True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if all elements\n",
      " |          are True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).all()\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"ostrich\", \"penguin\", \"parrot\"])\n",
      " |      >>> df\n",
      " |               a  b  c\n",
      " |      ostrich  1  0  3\n",
      " |      penguin  1  5  6\n",
      " |      parrot   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).all()\n",
      " |             b      c\n",
      " |      a\n",
      " |      1  False   True\n",
      " |      7   True   True\n",
      " |  \n",
      " |  any(self, skipna: 'bool' = True)\n",
      " |      Return True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if any element\n",
      " |          is True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).any()\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 3], [1, 0, 6], [7, 1, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"ostrich\", \"penguin\", \"parrot\"])\n",
      " |      >>> df\n",
      " |               a  b  c\n",
      " |      ostrich  1  0  3\n",
      " |      penguin  1  0  6\n",
      " |      parrot   7  1  9\n",
      " |      >>> df.groupby(by=[\"a\"]).any()\n",
      " |             b      c\n",
      " |      a\n",
      " |      1  False   True\n",
      " |      7   True   True\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Apply function ``func`` group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to ``apply`` must take a dataframe as its first\n",
      " |      argument and return a DataFrame, Series or scalar. ``apply`` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. ``apply`` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While ``apply`` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like ``agg`` or ``transform``. Pandas offers a wide range of method that will\n",
      " |      be much faster than using ``apply`` for their specific purposes, so try to\n",
      " |      use them before reaching for ``apply``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a dataframe as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': 'a a b'.split(),\n",
      " |      ...                    'B': [1,2,3],\n",
      " |      ...                    'C': [4,6,5]})\n",
      " |      >>> g1 = df.groupby('A', group_keys=False)\n",
      " |      >>> g2 = df.groupby('A', group_keys=True)\n",
      " |      \n",
      " |      Notice that ``g1`` and ``g2`` have two groups, ``a`` and ``b``, and only\n",
      " |      differ in their ``group_keys`` argument. Calling `apply` in various ways,\n",
      " |      we can get different grouping results:\n",
      " |      \n",
      " |      Example 1: below the function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a DataFrame. `apply` combines the result for\n",
      " |      each group together into a new DataFrame:\n",
      " |      \n",
      " |      >>> g1[['B', 'C']].apply(lambda x: x / x.sum())\n",
      " |                B    C\n",
      " |      0  0.333333  0.4\n",
      " |      1  0.666667  0.6\n",
      " |      2  1.000000  1.0\n",
      " |      \n",
      " |      In the above, the groups are not part of the index. We can have them included\n",
      " |      by using ``g2`` where ``group_keys=True``:\n",
      " |      \n",
      " |      >>> g2[['B', 'C']].apply(lambda x: x / x.sum())\n",
      " |                  B    C\n",
      " |      A\n",
      " |      a 0  0.333333  0.4\n",
      " |        1  0.666667  0.6\n",
      " |      b 2  1.000000  1.0\n",
      " |      \n",
      " |      Example 2: The function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a Series.  `apply` combines the result for\n",
      " |      each group together into a new DataFrame.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``.\n",
      " |      \n",
      " |      >>> g1[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())\n",
      " |           B    C\n",
      " |      A\n",
      " |      a  1.0  2.0\n",
      " |      b  0.0  0.0\n",
      " |      \n",
      " |      >>> g2[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())\n",
      " |           B    C\n",
      " |      A\n",
      " |      a  1.0  2.0\n",
      " |      b  0.0  0.0\n",
      " |      \n",
      " |      The ``group_keys`` argument has no effect here because the result is not\n",
      " |      like-indexed (i.e. :ref:`a transform <groupby.transform>`) when compared\n",
      " |      to the input.\n",
      " |      \n",
      " |      Example 3: The function passed to `apply` takes a DataFrame as\n",
      " |      its argument and returns a scalar. `apply` combines the result for\n",
      " |      each group together into a Series, including setting the index as\n",
      " |      appropriate:\n",
      " |      \n",
      " |      >>> g1.apply(lambda x: x.C.max() - x.B.min())\n",
      " |      A\n",
      " |      a    5\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  bfill(self, limit: 'int | None' = None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.bfill :  Backward fill the missing values in the dataset.\n",
      " |      DataFrame.bfill:  Backward fill the missing values in the dataset.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      With Series:\n",
      " |      \n",
      " |      >>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']\n",
      " |      >>> s = pd.Series([None, 1, None, None, 3], index=index)\n",
      " |      >>> s\n",
      " |      Falcon    NaN\n",
      " |      Falcon    1.0\n",
      " |      Parrot    NaN\n",
      " |      Parrot    NaN\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.groupby(level=0).bfill()\n",
      " |      Falcon    1.0\n",
      " |      Falcon    1.0\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.groupby(level=0).bfill(limit=1)\n",
      " |      Falcon    1.0\n",
      " |      Falcon    1.0\n",
      " |      Parrot    NaN\n",
      " |      Parrot    3.0\n",
      " |      Parrot    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      With DataFrame:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, None, None, None, 4],\n",
      " |      ...                    'B': [None, None, 5, None, 7]}, index=index)\n",
      " |      >>> df\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  NaN       5.0\n",
      " |      Parrot  NaN       NaN\n",
      " |      Parrot  4.0       7.0\n",
      " |      >>> df.groupby(level=0).bfill()\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  4.0       5.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      >>> df.groupby(level=0).bfill(limit=1)\n",
      " |                A         B\n",
      " |      Falcon  1.0       NaN\n",
      " |      Falcon  NaN       NaN\n",
      " |      Parrot  NaN       5.0\n",
      " |      Parrot  4.0       7.0\n",
      " |      Parrot  4.0       7.0\n",
      " |  \n",
      " |  count(self) -> 'NDFrameT'\n",
      " |      Compute count of group, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Count of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, np.nan], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1.0\n",
      " |      a    2.0\n",
      " |      b    NaN\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).count()\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a         b     c\n",
      " |      cow     1       NaN     3\n",
      " |      horse   1       NaN     6\n",
      " |      bull    7       8.0     9\n",
      " |      >>> df.groupby(\"a\").count()\n",
      " |          b   c\n",
      " |      a\n",
      " |      1   0   2\n",
      " |      7   1   1\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').count()\n",
      " |      2023-01-01    2\n",
      " |      2023-02-01    2\n",
      " |      Freq: MS, dtype: int64\n",
      " |  \n",
      " |  cumcount(self, ascending: 'bool' = True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Sequence number of each element within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis: 'AxisInt | lib.NoDefault' = <no_default>, numeric_only: 'bool' = False, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 6, 2, 3, 1, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    1\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cummax()\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    6\n",
      " |      b    3\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 1, 0], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      cow     1   8   2\n",
      " |      horse   1   1   0\n",
      " |      bull    2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['cow', 'horse'], 2: ['bull']}\n",
      " |      >>> df.groupby(\"a\").cummax()\n",
      " |              b   c\n",
      " |      cow     8   2\n",
      " |      horse   8   2\n",
      " |      bull    6   9\n",
      " |  \n",
      " |  cummin(self, axis: 'AxisInt | lib.NoDefault' = <no_default>, numeric_only: 'bool' = False, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 6, 2, 3, 0, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    0\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cummin()\n",
      " |      a    1\n",
      " |      a    1\n",
      " |      a    1\n",
      " |      b    3\n",
      " |      b    0\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 0, 2], [1, 1, 5], [6, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"snake\", \"rabbit\", \"turtle\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      snake   1   0   2\n",
      " |      rabbit  1   1   5\n",
      " |      turtle  6   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['snake', 'rabbit'], 6: ['turtle']}\n",
      " |      >>> df.groupby(\"a\").cummin()\n",
      " |              b   c\n",
      " |      snake   0   2\n",
      " |      rabbit  0   2\n",
      " |      turtle  6   9\n",
      " |  \n",
      " |  cumprod(self, axis: 'Axis | lib.NoDefault' = <no_default>, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([6, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cumprod()\n",
      " |      a    6\n",
      " |      a   12\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"cow\", \"horse\", \"bull\"])\n",
      " |      >>> df\n",
      " |              a   b   c\n",
      " |      cow     1   8   2\n",
      " |      horse   1   2   5\n",
      " |      bull    2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['cow', 'horse'], 2: ['bull']}\n",
      " |      >>> df.groupby(\"a\").cumprod()\n",
      " |              b   c\n",
      " |      cow     8   2\n",
      " |      horse  16  10\n",
      " |      bull    6   9\n",
      " |  \n",
      " |  cumsum(self, axis: 'Axis | lib.NoDefault' = <no_default>, *args, **kwargs) -> 'NDFrameT'\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([6, 2, 0], index=lst)\n",
      " |      >>> ser\n",
      " |      a    6\n",
      " |      a    2\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).cumsum()\n",
      " |      a    6\n",
      " |      a    8\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"fox\", \"gorilla\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a   b   c\n",
      " |      fox       1   8   2\n",
      " |      gorilla   1   2   5\n",
      " |      lion      2   6   9\n",
      " |      >>> df.groupby(\"a\").groups\n",
      " |      {1: ['fox', 'gorilla'], 2: ['lion']}\n",
      " |      >>> df.groupby(\"a\").cumsum()\n",
      " |                b   c\n",
      " |      fox       8   2\n",
      " |      gorilla  10   7\n",
      " |      lion      6   9\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None) -> 'NDFrameT'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...     np.datetime64(\"2000-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'AxisInt | lib.NoDefault' = <no_default>) -> 'NDFrameT'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of each element compared with another\n",
      " |      element in the group (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative values.\n",
      " |      axis : axis to shift, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          First differences.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).diff()\n",
      " |      a    NaN\n",
      " |      a   -5.0\n",
      " |      a    6.0\n",
      " |      b    NaN\n",
      " |      b   -1.0\n",
      " |      b    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).diff()\n",
      " |               a    b\n",
      " |        dog  NaN  NaN\n",
      " |        dog  2.0  3.0\n",
      " |        dog  2.0  4.0\n",
      " |      mouse  NaN  NaN\n",
      " |      mouse  0.0  0.0\n",
      " |      mouse  1.0 -2.0\n",
      " |      mouse -5.0 -1.0\n",
      " |  \n",
      " |  ewm(self, *args, **kwargs) -> 'ExponentialMovingWindowGroupby'\n",
      " |      Return an ewm grouper, providing ewm functionality per group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExponentialMovingWindowGroupby\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs) -> 'ExpandingGroupby'\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExpandingGroupby\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  ffill(self, limit: 'int | None' = None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.ffill: Returns Series with minimum number of char in object.\n",
      " |      DataFrame.ffill: Object with missing values filled or None if inplace=True.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> key = [0, 0, 1, 1]\n",
      " |      >>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)\n",
      " |      >>> ser\n",
      " |      0    NaN\n",
      " |      0    2.0\n",
      " |      1    3.0\n",
      " |      1    NaN\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).ffill()\n",
      " |      0    NaN\n",
      " |      0    2.0\n",
      " |      1    3.0\n",
      " |      1    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"key\": [0, 0, 1, 1, 1],\n",
      " |      ...         \"A\": [np.nan, 2, np.nan, 3, np.nan],\n",
      " |      ...         \"B\": [2, 3, np.nan, np.nan, np.nan],\n",
      " |      ...         \"C\": [np.nan, np.nan, 2, np.nan, np.nan],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         key    A    B   C\n",
      " |      0    0  NaN  2.0 NaN\n",
      " |      1    0  2.0  3.0 NaN\n",
      " |      2    1  NaN  NaN 2.0\n",
      " |      3    1  3.0  NaN NaN\n",
      " |      4    1  NaN  NaN NaN\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along columns.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").ffill()\n",
      " |           A    B   C\n",
      " |      0  NaN  2.0 NaN\n",
      " |      1  2.0  3.0 NaN\n",
      " |      2  NaN  NaN 2.0\n",
      " |      3  3.0  NaN 2.0\n",
      " |      4  3.0  NaN 2.0\n",
      " |      \n",
      " |      Propagate non-null values forward or backward within each group along rows.\n",
      " |      \n",
      " |      >>> df.T.groupby(np.array([0, 0, 1, 1])).ffill().T\n",
      " |         key    A    B    C\n",
      " |      0  0.0  0.0  2.0  2.0\n",
      " |      1  0.0  2.0  3.0  3.0\n",
      " |      2  1.0  1.0  NaN  2.0\n",
      " |      3  1.0  3.0  NaN  NaN\n",
      " |      4  1.0  1.0  NaN  NaN\n",
      " |      \n",
      " |      Only replace the first NaN element within a group along rows.\n",
      " |      \n",
      " |      >>> df.groupby(\"key\").ffill(limit=1)\n",
      " |           A    B    C\n",
      " |      0  NaN  2.0  NaN\n",
      " |      1  2.0  3.0  NaN\n",
      " |      2  NaN  NaN  2.0\n",
      " |      3  3.0  NaN  2.0\n",
      " |      4  3.0  NaN  NaN\n",
      " |  \n",
      " |  first(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute the first non-null entry of each column.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          First non-null of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby : Apply a function groupby to each row or column of a\n",
      " |          DataFrame.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.last : Compute the last non-null entry\n",
      " |          of each column.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],\n",
      " |      ...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))\n",
      " |      >>> df['D'] = pd.to_datetime(df['D'])\n",
      " |      >>> df.groupby(\"A\").first()\n",
      " |           B  C          D\n",
      " |      A\n",
      " |      1  5.0  1 2000-03-11\n",
      " |      3  6.0  3 2000-03-13\n",
      " |      >>> df.groupby(\"A\").first(min_count=2)\n",
      " |          B    C          D\n",
      " |      A\n",
      " |      1 NaN  1.0 2000-03-11\n",
      " |      3 NaN  NaN        NaT\n",
      " |      >>> df.groupby(\"A\").first(numeric_only=True)\n",
      " |           B  C\n",
      " |      A\n",
      " |      1  5.0  1\n",
      " |      3  6.0  3\n",
      " |  \n",
      " |  head(self, n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return first n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from start of each group.\n",
      " |          If negative: number of entries to exclude from end of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(-1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |  \n",
      " |  last(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute the last non-null entry of each column.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Last non-null of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.groupby : Apply a function groupby to each row or column of a\n",
      " |          DataFrame.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.first : Compute the first non-null entry\n",
      " |          of each column.\n",
      " |      pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))\n",
      " |      >>> df.groupby(\"A\").last()\n",
      " |           B  C\n",
      " |      A\n",
      " |      1  5.0  2\n",
      " |      3  6.0  3\n",
      " |  \n",
      " |  max(self, numeric_only: 'bool' = False, min_count: 'int' = -1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute max of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed max of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).max()\n",
      " |      a    2\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").max()\n",
      " |          b  c\n",
      " |      a\n",
      " |      1   8  5\n",
      " |      2   6  9\n",
      " |  \n",
      " |  mean(self, numeric_only: 'bool' = False, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None`` and defaults to ``False``.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |               C\n",
      " |      A B\n",
      " |      1 2.0  2.0\n",
      " |        4.0  1.0\n",
      " |      2 3.0  1.0\n",
      " |        5.0  2.0\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, numeric_only: 'bool' = False)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None`` and defaults to False.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Median of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).median()\n",
      " |      a    7.0\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).median()\n",
      " |               a    b\n",
      " |      dog    3.0  4.0\n",
      " |      mouse  7.0  3.0\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 3, 4, 5],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').median()\n",
      " |      2023-01-01    2.0\n",
      " |      2023-02-01    4.0\n",
      " |      Freq: MS, dtype: float64\n",
      " |  \n",
      " |  min(self, numeric_only: 'bool' = False, min_count: 'int' = -1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute min of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed min of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).min()\n",
      " |      a    1\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").min()\n",
      " |          b  c\n",
      " |      a\n",
      " |      1   2  2\n",
      " |      2   5  8\n",
      " |  \n",
      " |  ngroup(self, ascending: 'bool' = True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      Groups with missing keys (where `pd.isna()` is True) will be labeled with `NaN`\n",
      " |      and will be skipped from the count.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Unique numbers for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"color\": [\"red\", None, \"red\", \"blue\", \"blue\", \"red\"]})\n",
      " |      >>> df\n",
      " |         color\n",
      " |      0    red\n",
      " |      1   None\n",
      " |      2    red\n",
      " |      3   blue\n",
      " |      4   blue\n",
      " |      5    red\n",
      " |      >>> df.groupby(\"color\").ngroup()\n",
      " |      0    1.0\n",
      " |      1    NaN\n",
      " |      2    1.0\n",
      " |      3    0.0\n",
      " |      4    0.0\n",
      " |      5    1.0\n",
      " |      dtype: float64\n",
      " |      >>> df.groupby(\"color\", dropna=False).ngroup()\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby(\"color\", dropna=False).ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    2\n",
      " |      4    2\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  ohlc(self) -> 'DataFrame'\n",
      " |      Compute open, high, low and close values of a group, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Open, high, low and close values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]\n",
      " |      >>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)\n",
      " |      >>> ser\n",
      " |      SPX     3.4\n",
      " |      CAC     9.0\n",
      " |      SPX     7.2\n",
      " |      CAC     5.2\n",
      " |      SPX     8.8\n",
      " |      CAC     9.4\n",
      " |      SPX     0.1\n",
      " |      CAC     0.5\n",
      " |      dtype: float64\n",
      " |      >>> ser.groupby(level=0).ohlc()\n",
      " |           open  high  low  close\n",
      " |      CAC   9.0   9.4  0.5    0.5\n",
      " |      SPX   3.4   8.8  0.1    0.1\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],\n",
      " |      ...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}\n",
      " |      >>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',\n",
      " |      ...                   'SPX', 'CAC', 'SPX', 'CAC'])\n",
      " |      >>> df\n",
      " |           2022  2023\n",
      " |      SPX   1.2   3.4\n",
      " |      CAC   2.3   9.0\n",
      " |      SPX   8.9   7.2\n",
      " |      CAC   4.5   5.2\n",
      " |      SPX   4.4   8.8\n",
      " |      CAC   3.0   9.4\n",
      " |      SPX   2.0   8.2\n",
      " |      CAC   1.0   1.0\n",
      " |      >>> df.groupby(level=0).ohlc()\n",
      " |          2022                 2023\n",
      " |          open high  low close open high  low close\n",
      " |      CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0\n",
      " |      SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 3, 2, 4, 3, 5],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').ohlc()\n",
      " |                  open  high  low  close\n",
      " |      2023-01-01     1     3    1      2\n",
      " |      2023-02-01     4     5    3      5\n",
      " |  \n",
      " |  pct_change(self, periods: 'int' = 1, fill_method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, freq=None, axis: 'Axis | lib.NoDefault' = <no_default>)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Percentage changes within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).pct_change()\n",
      " |      a         NaN\n",
      " |      a    1.000000\n",
      " |      b         NaN\n",
      " |      b    0.333333\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a  b  c\n",
      " |          tuna   1  2  3\n",
      " |        salmon   1  5  6\n",
      " |       catfish   2  5  8\n",
      " |      goldfish   2  6  9\n",
      " |      >>> df.groupby(\"a\").pct_change()\n",
      " |                  b  c\n",
      " |          tuna    NaN    NaN\n",
      " |        salmon    1.5  1.000\n",
      " |       catfish    NaN    NaN\n",
      " |      goldfish    0.2  0.125\n",
      " |  \n",
      " |  prod(self, numeric_only: 'bool' = False, min_count: 'int' = 0)\n",
      " |      Compute prod of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed prod of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).prod()\n",
      " |      a    2\n",
      " |      b   12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").prod()\n",
      " |           b    c\n",
      " |      a\n",
      " |      1   16   10\n",
      " |      2   30   72\n",
      " |  \n",
      " |  quantile(self, q: 'float | AnyArrayLike' = 0.5, interpolation: 'str' = 'linear', numeric_only: 'bool' = False)\n",
      " |      Return group values at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          Method to use when the desired quantile falls between two points.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return type determined by caller of GroupBy object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.quantile : Similar method for Series.\n",
      " |      DataFrame.quantile : Similar method for DataFrame.\n",
      " |      numpy.percentile : NumPy method to compute qth percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      " |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      " |      ... ], columns=['key', 'val'])\n",
      " |      >>> df.groupby('key').quantile()\n",
      " |          val\n",
      " |      key\n",
      " |      a    2.0\n",
      " |      b    3.0\n",
      " |  \n",
      " |  rank(self, method: 'str' = 'average', ascending: 'bool' = True, na_option: 'str' = 'keep', pct: 'bool' = False, axis: 'AxisInt | lib.NoDefault' = <no_default>) -> 'NDFrameT'\n",
      " |      Provide the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group.\n",
      " |          * min: lowest rank in group.\n",
      " |          * max: highest rank in group.\n",
      " |          * first: ranks assigned in order they appear in the array.\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      ascending : bool, default True\n",
      " |          False for ranks by high (1) to low (N).\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are.\n",
      " |          * top: smallest rank if ascending.\n",
      " |          * bottom: smallest rank if descending.\n",
      " |      pct : bool, default False\n",
      " |          Compute percentage rank of data within each group.\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"group\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n",
      " |      ...         \"value\": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        group  value\n",
      " |      0     a      2\n",
      " |      1     a      4\n",
      " |      2     a      2\n",
      " |      3     a      3\n",
      " |      4     a      5\n",
      " |      5     b      1\n",
      " |      6     b      2\n",
      " |      7     b      4\n",
      " |      8     b      1\n",
      " |      9     b      5\n",
      " |      >>> for method in ['average', 'min', 'max', 'dense', 'first']:\n",
      " |      ...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)\n",
      " |      >>> df\n",
      " |        group  value  average_rank  min_rank  max_rank  dense_rank  first_rank\n",
      " |      0     a      2           1.5       1.0       2.0         1.0         1.0\n",
      " |      1     a      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      2     a      2           1.5       1.0       2.0         1.0         2.0\n",
      " |      3     a      3           3.0       3.0       3.0         2.0         3.0\n",
      " |      4     a      5           5.0       5.0       5.0         4.0         5.0\n",
      " |      5     b      1           1.5       1.0       2.0         1.0         1.0\n",
      " |      6     b      2           3.0       3.0       3.0         2.0         3.0\n",
      " |      7     b      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      8     b      1           1.5       1.0       2.0         1.0         2.0\n",
      " |      9     b      5           5.0       5.0       5.0         4.0         5.0\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.DatetimeIndexResamplerGroupby,\n",
      " |      pandas.api.typing.PeriodIndexResamplerGroupby, or\n",
      " |      pandas.api.typing.TimedeltaIndexResamplerGroupby\n",
      " |          Return a new groupby object, with type depending on the data\n",
      " |          being resampled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs) -> 'RollingGroupby'\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, timedelta, str, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |      \n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |      \n",
      " |          If a timedelta, str, or offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |      \n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |          For a window that is specified by an offset,\n",
      " |          ``min_periods`` will default to 1.\n",
      " |      \n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |      \n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |      \n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'both'``, no points in the window are excluded from calculations.\n",
      " |      \n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |      \n",
      " |          Default ``None`` (``'right'``).\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.RollingGroupby\n",
      " |          Return a new grouper with our rolling appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rolling : Calling object with Series data.\n",
      " |      DataFrame.rolling : Calling object with DataFrames.\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': [0.362, 0.227, 1.267, -0.562]})\n",
      " |      >>> df\n",
      " |            A  B      C\n",
      " |      0     1  1  0.362\n",
      " |      1     1  2  0.227\n",
      " |      2     2  3  1.267\n",
      " |      3     2  4 -0.562\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2).sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  NaN    NaN\n",
      " |        1  3.0  0.589\n",
      " |      2 2  NaN    NaN\n",
      " |        3  7.0  0.705\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2, min_periods=1).sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  1.0  0.362\n",
      " |        1  3.0  0.589\n",
      " |      2 2  3.0  1.267\n",
      " |        3  7.0  0.705\n",
      " |      \n",
      " |      >>> df.groupby('A').rolling(2, on='B').sum()\n",
      " |          B      C\n",
      " |      A\n",
      " |      1 0  1    NaN\n",
      " |        1  2  0.589\n",
      " |      2 2  3    NaN\n",
      " |        3  4  0.705\n",
      " |  \n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool' = False, weights: 'Sequence | Series | None' = None, random_state: 'RandomState | None' = None)\n",
      " |      Return a random sample of items from each group.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items to return for each group. Cannot be used with\n",
      " |          `frac` and must be no larger than the smallest group unless\n",
      " |          `replace` is True. Default is one if `frac` is None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : list-like, optional\n",
      " |          Default None results in equal probability weighting.\n",
      " |          If passed a list-like then values must have the same length as\n",
      " |          the underlying DataFrame or Series object and will be used as\n",
      " |          sampling probabilities after normalization within each group.\n",
      " |          Values must be non-negative with at least one positive element\n",
      " |          within each group.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing items randomly\n",
      " |          sampled within each group from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sample: Generate random samples from a DataFrame object.\n",
      " |      numpy.random.choice: Generate a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)}\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |             a  b\n",
      " |      0    red  0\n",
      " |      1    red  1\n",
      " |      2   blue  2\n",
      " |      3   blue  3\n",
      " |      4  black  4\n",
      " |      5  black  5\n",
      " |      \n",
      " |      Select one row at random for each distinct value in column a. The\n",
      " |      `random_state` argument can be used to guarantee reproducibility:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(n=1, random_state=1)\n",
      " |             a  b\n",
      " |      4  black  4\n",
      " |      2   blue  2\n",
      " |      1    red  1\n",
      " |      \n",
      " |      Set `frac` to sample fixed proportions rather than counts:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\")[\"b\"].sample(frac=0.5, random_state=2)\n",
      " |      5    5\n",
      " |      2    2\n",
      " |      0    0\n",
      " |      Name: b, dtype: int64\n",
      " |      \n",
      " |      Control sample probabilities within groups by setting weights:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(\n",
      " |      ...     n=1,\n",
      " |      ...     weights=[1, 1, 1, 0, 0, 1],\n",
      " |      ...     random_state=1,\n",
      " |      ... )\n",
      " |             a  b\n",
      " |      5  black  5\n",
      " |      2   blue  2\n",
      " |      0    red  0\n",
      " |  \n",
      " |  sem(self, ddof: 'int' = 1, numeric_only: 'bool' = False)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard error of the mean of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([5, 10, 8, 14], index=lst)\n",
      " |      >>> ser\n",
      " |      a     5\n",
      " |      a    10\n",
      " |      b     8\n",
      " |      b    14\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).sem()\n",
      " |      a    2.5\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a   b   c\n",
      " |          tuna   1  12  11\n",
      " |        salmon   1  15   2\n",
      " |       catfish   2   5   8\n",
      " |      goldfish   2   6  12\n",
      " |      >>> df.groupby(\"a\").sem()\n",
      " |            b  c\n",
      " |      a\n",
      " |      1    1.5  4.5\n",
      " |      2    0.5  2.0\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 3, 2, 4, 3, 8],\n",
      " |      ...                 index=pd.DatetimeIndex(['2023-01-01',\n",
      " |      ...                                         '2023-01-10',\n",
      " |      ...                                         '2023-01-15',\n",
      " |      ...                                         '2023-02-01',\n",
      " |      ...                                         '2023-02-10',\n",
      " |      ...                                         '2023-02-15']))\n",
      " |      >>> ser.resample('MS').sem()\n",
      " |      2023-01-01    0.577350\n",
      " |      2023-02-01    1.527525\n",
      " |      Freq: MS, dtype: float64\n",
      " |  \n",
      " |  shift(self, periods: 'int | Sequence[int]' = 1, freq=None, axis: 'Axis | lib.NoDefault' = <no_default>, fill_value=<no_default>, suffix: 'str | None' = None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      If freq is passed, the index will be increased using the periods and the freq.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int | Sequence[int], default 1\n",
      " |          Number of periods to shift. If a list of values, shift each group by\n",
      " |          each period.\n",
      " |      freq : str, optional\n",
      " |          Frequency string.\n",
      " |      axis : axis to shift, default 0\n",
      " |          Shift direction.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              For axis=1, operate on the underlying object instead. Otherwise\n",
      " |              the axis keyword is not necessary.\n",
      " |      \n",
      " |      fill_value : optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |      \n",
      " |          .. versionchanged:: 2.1.0\n",
      " |              Will raise a ``ValueError`` if ``freq`` is provided too.\n",
      " |      \n",
      " |      suffix : str, optional\n",
      " |          A string to add to each shifted column if there are multiple periods.\n",
      " |          Ignored otherwise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object shifted within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).shift(1)\n",
      " |      a    NaN\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      b    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tuna\", \"salmon\", \"catfish\", \"goldfish\"])\n",
      " |      >>> df\n",
      " |                 a  b  c\n",
      " |          tuna   1  2  3\n",
      " |        salmon   1  5  6\n",
      " |       catfish   2  5  8\n",
      " |      goldfish   2  6  9\n",
      " |      >>> df.groupby(\"a\").shift(1)\n",
      " |                    b    c\n",
      " |          tuna    NaN  NaN\n",
      " |        salmon    2.0  3.0\n",
      " |       catfish    NaN  NaN\n",
      " |      goldfish    5.0  8.0\n",
      " |  \n",
      " |  size(self) -> 'DataFrame | Series'\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Number of rows in each group as a Series if as_index is True\n",
      " |          or a DataFrame if as_index is False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     1\n",
      " |      a     2\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).size()\n",
      " |      a    2\n",
      " |      b    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(\"a\").size()\n",
      " |      a\n",
      " |      1    2\n",
      " |      7    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').size()\n",
      " |      2023-01-01    2\n",
      " |      2023-02-01    1\n",
      " |      Freq: MS, dtype: int64\n",
      " |  \n",
      " |  std(self, ddof: 'int' = 1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None, numeric_only: 'bool' = False)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard deviation of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).std()\n",
      " |      a    3.21455\n",
      " |      b    0.57735\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).std()\n",
      " |                    a         b\n",
      " |      dog    2.000000  3.511885\n",
      " |      mouse  2.217356  1.500000\n",
      " |  \n",
      " |  sum(self, numeric_only: 'bool' = False, min_count: 'int' = 0, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute sum of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only no longer accepts ``None``.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      engine : str, default None None\n",
      " |          * ``'cython'`` : Runs rolling apply through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.\n",
      " |              Only available when ``raw`` is set to ``True``.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |      engine_kwargs : dict, default None None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |              and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |              ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |              applied to both the ``func`` and the ``apply`` groupby aggregation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed sum of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).sum()\n",
      " |      a    3\n",
      " |      b    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"tiger\", \"leopard\", \"cheetah\", \"lion\"])\n",
      " |      >>> df\n",
      " |                a  b  c\n",
      " |        tiger   1  8  2\n",
      " |      leopard   1  2  5\n",
      " |      cheetah   2  5  8\n",
      " |         lion   2  6  9\n",
      " |      >>> df.groupby(\"a\").sum()\n",
      " |           b   c\n",
      " |      a\n",
      " |      1   10   7\n",
      " |      2   11  17\n",
      " |  \n",
      " |  tail(self, n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return last n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from end of each group.\n",
      " |          If negative: number of entries to exclude from start of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').tail(-1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |  \n",
      " |  var(self, ddof: 'int' = 1, engine: \"Literal['cython', 'numba'] | None\" = None, engine_kwargs: 'dict[str, bool] | None' = None, numeric_only: 'bool' = False)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              numeric_only now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Variance of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |      >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a     7\n",
      " |      a     2\n",
      " |      a     8\n",
      " |      b     4\n",
      " |      b     3\n",
      " |      b     3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).var()\n",
      " |      a    10.333333\n",
      " |      b     0.333333\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}\n",
      " |      >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',\n",
      " |      ...                   'mouse', 'mouse', 'mouse', 'mouse'])\n",
      " |      >>> df\n",
      " |               a  b\n",
      " |        dog    1  1\n",
      " |        dog    3  4\n",
      " |        dog    5  8\n",
      " |      mouse    7  4\n",
      " |      mouse    7  4\n",
      " |      mouse    8  2\n",
      " |      mouse    3  1\n",
      " |      >>> df.groupby(level=0).var()\n",
      " |                    a          b\n",
      " |      dog    4.000000  12.333333\n",
      " |      mouse  4.916667   2.250000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  nth\n",
      " |      Take the nth row from each group if n is an int, otherwise a subset of rows.\n",
      " |      \n",
      " |      Can be either a call or an index. dropna is not available with index notation.\n",
      " |      Index notation accepts a comma separated list of integers and slices.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      " |      before the groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, slice or list of ints and slices\n",
      " |          A single nth value for the row or a list of nth values or slices.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Added slice and lists containing slices.\n",
      " |              Added index notation.\n",
      " |      \n",
      " |      dropna : {'any', 'all', None}, default None\n",
      " |          Apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Only supported if n is an int.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          N-th value within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      2  2 3.0\n",
      " |      >>> g.nth(1)\n",
      " |         A   B\n",
      " |      1  1 2.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth(-1)\n",
      " |         A   B\n",
      " |      3  1 4.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth(slice(None, -1))\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      Index notation may also be used\n",
      " |      \n",
      " |      >>> g.nth[0, 1]\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      4  2 5.0\n",
      " |      >>> g.nth[:-1]\n",
      " |         A   B\n",
      " |      0  1 NaN\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      Specifying `dropna` allows ignoring ``NaN`` values\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |         A   B\n",
      " |      1  1 2.0\n",
      " |      2  2 3.0\n",
      " |      \n",
      " |      When the specified ``n`` is larger than any of the groups, an\n",
      " |      empty DataFrame is returned\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A, B]\n",
      " |      Index: []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  __iter__(self) -> 'Iterator[tuple[Hashable, NDFrameT]]'\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> for x, y in ser.groupby(level=0):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      a\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      dtype: int64\n",
      " |      b\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n",
      " |      >>> df\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      2  7  8  9\n",
      " |      >>> for x, y in df.groupby(by=[\"a\"]):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      (1,)\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      (7,)\n",
      " |         a  b  c\n",
      " |      2  7  8  9\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> for x, y in ser.resample('MS'):\n",
      " |      ...     print(f'{x}\\n{y}\\n')\n",
      " |      2023-01-01 00:00:00\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      dtype: int64\n",
      " |      2023-02-01 00:00:00\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular object.\n",
      " |  \n",
      " |  get_group(self, name, obj=None) -> 'DataFrame | Series'\n",
      " |      Construct DataFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          The name of the group to get as a DataFrame.\n",
      " |      obj : DataFrame, default None\n",
      " |          The DataFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used.\n",
      " |      \n",
      " |          .. deprecated:: 2.1.0\n",
      " |              The obj is deprecated and will be removed in a future version.\n",
      " |              Do ``df.iloc[gb.indices.get(name)]``\n",
      " |              instead of ``gb.get_group(name, obj=df)``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as obj\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).get_group(\"a\")\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).get_group(1)\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').get_group('2023-01-01')\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply a ``func`` with arguments to this GroupBy object and return its result.\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))  # doctest: +SKIP\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, str)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             Positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               A dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pipe : Apply a function with arguments to a series.\n",
      " |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).groups\n",
      " |      {'a': ['a', 'a'], 'b': ['b']}\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"])\n",
      " |      >>> df\n",
      " |         a  b  c\n",
      " |      0  1  2  3\n",
      " |      1  1  5  6\n",
      " |      2  7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).groups\n",
      " |      {1: [0, 1], 7: [2]}\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').groups\n",
      " |      {Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For SeriesGroupBy:\n",
      " |      \n",
      " |      >>> lst = ['a', 'a', 'b']\n",
      " |      >>> ser = pd.Series([1, 2, 3], index=lst)\n",
      " |      >>> ser\n",
      " |      a    1\n",
      " |      a    2\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      >>> ser.groupby(level=0).indices\n",
      " |      {'a': array([0, 1]), 'b': array([2])}\n",
      " |      \n",
      " |      For DataFrameGroupBy:\n",
      " |      \n",
      " |      >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"a\", \"b\", \"c\"],\n",
      " |      ...                   index=[\"owl\", \"toucan\", \"eagle\"])\n",
      " |      >>> df\n",
      " |              a  b  c\n",
      " |      owl     1  2  3\n",
      " |      toucan  1  5  6\n",
      " |      eagle   7  8  9\n",
      " |      >>> df.groupby(by=[\"a\"]).indices\n",
      " |      {1: array([0, 1]), 7: array([2])}\n",
      " |      \n",
      " |      For Resampler:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(\n",
      " |      ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))\n",
      " |      >>> ser\n",
      " |      2023-01-01    1\n",
      " |      2023-01-15    2\n",
      " |      2023-02-01    3\n",
      " |      2023-02-15    4\n",
      " |      dtype: int64\n",
      " |      >>> ser.resample('MS').indices\n",
      " |      defaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],\n",
      " |      Timestamp('2023-02-01 00:00:00'): [2, 3]})\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  keys = None\n",
      " |  \n",
      " |  level = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |      Parameterizes a generic class.\n",
      " |      \n",
      " |      At least, parameterizing a generic class is the *main* thing this method\n",
      " |      does. For example, for some generic class `Foo`, this is called when we\n",
      " |      do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |      \n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo(Generic[T]): ...`.\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(titanic_subset.groupby('Sex'))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5c1d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "groupby object has many useful methods for processing data by group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648838a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Aggregation methods \n",
    "\n",
    "- Methods that compute statistics across the different groups.\n",
    "- Common aggregation methods:\n",
    "    - .min(): returns the minimum value for each column by group\n",
    "    - .max(): returns the maximum value for each column by group\n",
    "    - .mean(): returns the average value for each column by group\n",
    "    - .median(): returns the median value for each column by group\n",
    "    - .count(): returns the count of each column by group\n",
    "    - .sum(): return sum of each column by group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624681ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computing the mean of columns by group:\n",
    "- Note: mean of Survived is the survival fraction."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
=======
   "execution_count": 8,
>>>>>>> upstream/main
   "id": "9c943888",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.742038</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>44.479818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.188908</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>25.523893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived        Age       Fare\n",
       "Sex                                   \n",
       "female  0.742038  27.915709  44.479818\n",
       "male    0.188908  30.726645  25.523893"
      ]
     },
<<<<<<< HEAD
     "execution_count": 82,
=======
     "execution_count": 8,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf6ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Any obvious distinctions between groups here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e214d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### .agg(func) method\n",
    "Can write your own aggregations.\n",
    "- Get square root of the sum of squares of desired columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "912a1728",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>15.264338</td>\n",
       "      <td>505.132532</td>\n",
       "      <td>1293.863603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>10.440307</td>\n",
       "      <td>724.618934</td>\n",
       "      <td>1203.237998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived         Age         Fare\n",
       "Sex                                       \n",
       "female  15.264338  505.132532  1293.863603\n",
       "male    10.440307  724.618934  1203.237998"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset.groupby('Sex').agg(lambda x: np.sqrt(np.sum(x**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b72e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### .transform(func) method\n",
    "- This is not an aggregation.\n",
    "- Transforms entries in each column differently according to their group.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1a61b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: standardize columns for each sex separately:\n",
    "\n",
    "- Subtract entries of columns in each sex category by the column mean for that sex.\n",
    "- Then divide by the standard deviation of fare for that sex."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 84,
=======
   "execution_count": 9,
>>>>>>> upstream/main
   "id": "4e3c2a6d",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sexdifferentiated = titanic_subset.groupby('Sex').transform(lambda col: (col - col.mean())/col.std() )\n",
    "sexdifferentiated['Sex'] = titanic_subset['Sex']\n",
    "#titanic_subset.apply(lambda col: (col - col.mean())/col.std(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 10,
>>>>>>> upstream/main
   "id": "e981452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>-0.594531</td>\n",
       "      <td>-0.423612</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>0.714684</td>\n",
       "      <td>0.462147</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>-0.135768</td>\n",
       "      <td>-0.630280</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>0.502071</td>\n",
       "      <td>0.148630</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>0.291136</td>\n",
       "      <td>-0.405067</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>-0.253890</td>\n",
       "      <td>-0.290320</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.588670</td>\n",
       "      <td>-0.631865</td>\n",
       "      <td>-0.249662</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>-1.693335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.362597</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>2.070299</td>\n",
       "      <td>-0.322018</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-0.482185</td>\n",
       "      <td>0.086751</td>\n",
       "      <td>-0.412022</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age      Fare     Sex\n",
       "0   -0.482185 -0.594531 -0.423612    male\n",
       "1    0.588670  0.714684  0.462147  female\n",
       "2    0.588670 -0.135768 -0.630280  female\n",
       "3    0.588670  0.502071  0.148630  female\n",
       "4   -0.482185  0.291136 -0.405067    male\n",
       "..        ...       ...       ...     ...\n",
       "886 -0.482185 -0.253890 -0.290320    male\n",
       "887  0.588670 -0.631865 -0.249662  female\n",
       "888 -1.693335       NaN -0.362597  female\n",
       "889  2.070299 -0.322018  0.103762    male\n",
       "890 -0.482185  0.086751 -0.412022    male\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 85,
=======
     "execution_count": 10,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexdifferentiated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185da2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Grouping by multiple categorical variables\n",
    "\n",
    "- Split data into multiple levels of groups. \n",
    "- Group by sex (Male/Female) with subgroups in each according to passenger class.\n",
    "\n",
    "df.groupby() takes in list of categorical columns to group on:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 86,
=======
   "execution_count": 11,
>>>>>>> upstream/main
   "id": "cd1eef20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000017561A51040>"
      ]
     },
     "execution_count": 86,
=======
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021BA5CC42D0>"
      ]
     },
     "execution_count": 11,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_subset2 = titanic_df[['Sex', 'Pclass', 'Survived', 'Age', 'Fare']]\n",
    "titanic_subset2.groupby(['Sex','Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c79fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculate mean of attributes within these groups/subgroups:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 14,
>>>>>>> upstream/main
   "id": "3534e9ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th colspan=\"3\" halign=\"left\">Survived</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Age</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Fare</th>\n",
=======
       "      <th colspan=\"2\" halign=\"left\">Survived</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Age</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Fare</th>\n",
>>>>>>> upstream/main
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
<<<<<<< HEAD
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
=======
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
>>>>>>> upstream/main
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
=======
>>>>>>> upstream/main
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">female</th>\n",
       "      <th>1</th>\n",
       "      <td>0.968085</td>\n",
<<<<<<< HEAD
       "      <td>1.0</td>\n",
       "      <td>0.176716</td>\n",
       "      <td>34.611765</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.612052</td>\n",
       "      <td>106.125798</td>\n",
       "      <td>82.66455</td>\n",
=======
       "      <td>0.176716</td>\n",
       "      <td>34.611765</td>\n",
       "      <td>13.612052</td>\n",
       "      <td>106.125798</td>\n",
>>>>>>> upstream/main
       "      <td>74.259988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921053</td>\n",
<<<<<<< HEAD
       "      <td>1.0</td>\n",
       "      <td>0.271448</td>\n",
       "      <td>28.722973</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.872702</td>\n",
       "      <td>21.970121</td>\n",
       "      <td>22.00000</td>\n",
=======
       "      <td>0.271448</td>\n",
       "      <td>28.722973</td>\n",
       "      <td>12.872702</td>\n",
       "      <td>21.970121</td>\n",
>>>>>>> upstream/main
       "      <td>10.891796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
<<<<<<< HEAD
       "      <td>0.5</td>\n",
       "      <td>0.501745</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>21.5</td>\n",
       "      <td>12.729964</td>\n",
       "      <td>16.118810</td>\n",
       "      <td>12.47500</td>\n",
=======
       "      <td>0.501745</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>12.729964</td>\n",
       "      <td>16.118810</td>\n",
>>>>>>> upstream/main
       "      <td>11.690314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">male</th>\n",
       "      <th>1</th>\n",
       "      <td>0.368852</td>\n",
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>0.484484</td>\n",
       "      <td>41.281386</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.139570</td>\n",
       "      <td>67.226127</td>\n",
       "      <td>41.26250</td>\n",
=======
       "      <td>0.484484</td>\n",
       "      <td>41.281386</td>\n",
       "      <td>15.139570</td>\n",
       "      <td>67.226127</td>\n",
>>>>>>> upstream/main
       "      <td>77.548021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157407</td>\n",
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>0.365882</td>\n",
       "      <td>30.740707</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.793894</td>\n",
       "      <td>19.741782</td>\n",
       "      <td>13.00000</td>\n",
=======
       "      <td>0.365882</td>\n",
       "      <td>30.740707</td>\n",
       "      <td>14.793894</td>\n",
       "      <td>19.741782</td>\n",
>>>>>>> upstream/main
       "      <td>14.922235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135447</td>\n",
<<<<<<< HEAD
       "      <td>0.0</td>\n",
       "      <td>0.342694</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.159514</td>\n",
       "      <td>12.661633</td>\n",
       "      <td>7.92500</td>\n",
=======
       "      <td>0.342694</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>12.159514</td>\n",
       "      <td>12.661633</td>\n",
>>>>>>> upstream/main
       "      <td>11.681696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "               Survived                         Age                    \\\n",
       "                   mean median       std       mean median        std   \n",
       "Sex    Pclass                                                           \n",
       "female 1       0.968085    1.0  0.176716  34.611765   35.0  13.612052   \n",
       "       2       0.921053    1.0  0.271448  28.722973   28.0  12.872702   \n",
       "       3       0.500000    0.5  0.501745  21.750000   21.5  12.729964   \n",
       "male   1       0.368852    0.0  0.484484  41.281386   40.0  15.139570   \n",
       "       2       0.157407    0.0  0.365882  30.740707   30.0  14.793894   \n",
       "       3       0.135447    0.0  0.342694  26.507589   25.0  12.159514   \n",
       "\n",
       "                     Fare                       \n",
       "                     mean    median        std  \n",
       "Sex    Pclass                                   \n",
       "female 1       106.125798  82.66455  74.259988  \n",
       "       2        21.970121  22.00000  10.891796  \n",
       "       3        16.118810  12.47500  11.690314  \n",
       "male   1        67.226127  41.26250  77.548021  \n",
       "       2        19.741782  13.00000  14.922235  \n",
       "       3        12.661633   7.92500  11.681696  "
      ]
     },
     "execution_count": 87,
=======
       "               Survived                  Age                   Fare           \n",
       "                   mean       std       mean        std        mean        std\n",
       "Sex    Pclass                                                                 \n",
       "female 1       0.968085  0.176716  34.611765  13.612052  106.125798  74.259988\n",
       "       2       0.921053  0.271448  28.722973  12.872702   21.970121  10.891796\n",
       "       3       0.500000  0.501745  21.750000  12.729964   16.118810  11.690314\n",
       "male   1       0.368852  0.484484  41.281386  15.139570   67.226127  77.548021\n",
       "       2       0.157407  0.365882  30.740707  14.793894   19.741782  14.922235\n",
       "       3       0.135447  0.342694  26.507589  12.159514   12.661633  11.681696"
      ]
     },
     "execution_count": 14,
>>>>>>> upstream/main
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "grouped_df = titanic_subset2.groupby(['Sex','Pclass']).agg(['mean', 'median', 'std'])\n",
=======
    "grouped_df = titanic_subset2.groupby(['Sex','Pclass']).agg(['mean', 'std'])\n",
>>>>>>> upstream/main
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bdcbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The values are now set on a hierarchical multi-index.\n",
    "\n",
    "- Multi-indexing: extremely powerful.\n",
    "- Will cover the mechanics next lecture.\n",
    "\n",
    "Visualize survival rates and average fare paid by the subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3665a94a",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layout of 3x3 must be larger than required size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-eb75f84887eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# quick and dirty plot for sex/class disparity information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m grouped_df[['Survival', 'Fare']].unstack().plot.bar(subplots=True, layout = (3,3), figsize = (7,7),\n\u001b[0m\u001b[0;32m      8\u001b[0m                                                          legend = False, sharex = True)\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[0mother\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmeasured\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \"\"\"\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bar\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     @Appender(\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    947\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_setup_subplots\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             fig, axes = _subplots(\n\u001b[0m\u001b[0;32m    318\u001b[0m                 \u001b[0mnaxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnseries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py\u001b[0m in \u001b[0;36m_subplots\u001b[1;34m(naxes, sharex, sharey, squeeze, subplot_kw, ax, layout, layout_type, **fig_kw)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m     \u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnaxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[0mnplots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maktr\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(nplots, layout, layout_type)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mncols\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnplots\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[1;34mf\"Layout of {nrows}x{ncols} must be larger than required size {nplots}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Layout of 3x3 must be larger than required size 18"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a little column renaming\n",
    "grouped_df.rename(columns = {'Survived': 'Survival'}, \n",
    "                  index = {1: 'Class 1', 2: 'Class 2', 3: 'Class 3'}, inplace = True)\n",
    "grouped_df.index.set_names('Passenger class', level = 1, inplace = True)\n",
    "\n",
    "# quick and dirty plot for sex/class disparity information\n",
    "grouped_df[['Survival', 'Fare']].unstack().plot.bar(subplots=True, layout = (3,3), figsize = (7,7),\n",
    "                                                         legend = False, sharex = True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe792c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Essentially: \n",
    "- One groupby operation\n",
    "- One pandas plot call\n",
    "\n",
    "Result: informative visualization on sex/class disparity.\n",
    "\n",
    "Groupbys clearly allow us to start reforming data/asking interesting questions!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
